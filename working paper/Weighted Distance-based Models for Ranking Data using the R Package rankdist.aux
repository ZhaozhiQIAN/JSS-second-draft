\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{jss}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Critchlow1986}
\citation{AlvoYu2014}
\citation{Thurstone1927,Luce1959}
\citation{Yu2000,Joe2001}
\citation{Smith1950,Mallows1957}
\citation{Fligner1988}
\citation{Diaconis1988}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{Diaconis1988}
\citation{Mallows1957}
\newlabel{eq:dist_model_def}{{1}{3}{}{equation.2.1}{}}
\newlabel{sub:Mallows'--model}{{2.2}{3}{}{subsection.2.2}{}}
\citation{Fligner1986}
\citation{LeeYu2012}
\newlabel{eq:1}{{2}{4}{}{equation.2.2}{}}
\newlabel{eq:phi_component}{{3}{4}{}{equation.2.3}{}}
\newlabel{eq:phi_component_simp}{{4}{4}{}{equation.2.4}{}}
\citation{LeeYu2012}
\citation{LeeYu2012}
\citation{farnoud2014axiomatic}
\newlabel{sub:Weighted-Kendall-distance-model}{{2.4}{5}{}{subsection.2.4}{}}
\newlabel{sec:Geometrically-weighted-Kendall}{{3}{5}{}{section.3}{}}
\newlabel{eq:2}{{5}{5}{}{equation.3.5}{}}
\citation{farnoud2014axiomatic}
\citation{farnoud2014axiomatic}
\newlabel{eq:3}{{6}{6}{}{equation.3.6}{}}
\citation{dwork2001rank}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Graphical representation of weighted Kendall distance between four objects.}}{7}{figure.1}}
\newlabel{fig:Graphical-representation-of}{{1}{7}{Graphical representation of weighted Kendall distance between four objects}{figure.1}{}}
\newlabel{eq:4}{{7}{7}{}{equation.3.7}{}}
\newlabel{subsec:Estimating-central-ranking}{{3.3.1}{7}{}{subsubsection.3.3.1}{}}
\newlabel{eq:rank-agg-obj}{{8}{7}{}{equation.3.8}{}}
\citation{dwork2001rank}
\citation{young1974axiomatization}
\newlabel{subsec:Estimating-weights}{{3.3.2}{8}{}{subsubsection.3.3.2}{}}
\newlabel{subsec:Estimating-both}{{3.3.3}{9}{}{subsubsection.3.3.3}{}}
\newlabel{sub:Finite-mixture-of}{{4.1}{9}{}{subsection.4.1}{}}
\citation{Murphy2003}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces EM-algorithm for fitting mixture models}}{10}{algorithm.1}}
\newlabel{sub:Top--rankings}{{4.2}{10}{}{subsection.4.2}{}}
\newlabel{alg:Computing-weighted-Kendall}{{2}{11}{}{algorithm.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Computing weighted Kendall distance between top-$q$ rankings}}{11}{algorithm.2}}
\newlabel{eq:topq_likelihood}{{9}{11}{}{equation.4.9}{}}
\citation{PerMallows}
\citation{Rankcluster}
\citation{pmr}
\citation{mlogit}
\citation{ISR}
\citation{AlvoYu2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Flow chart of the model fitting procedure.}}{13}{figure.2}}
\newlabel{fig:flowchart}{{2}{13}{Flow chart of the model fitting procedure}{figure.2}{}}
\citation{R}
\citation{nash2011unifying}
\newlabel{sub:Estimation-of-weights}{{5.3}{14}{}{subsection.5.3}{}}
\newlabel{subsec:-Estimating-pi0-sim}{{7.1.2}{18}{}{subsubsection.7.1.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Distribution of Kendall distance between the true $\pi _{0}$ and the estimated ones. The results for two simulations with sample sizes 200 and 500. Type 'initial' represents the distance between the initial ranking (Borda count method) and true $\pi _{0}$, and type 'final' represents the distance between the ranking estimated by the algorithm and true $\pi _{0}$. The number in the cell represents the number of runs that the distance is observed. The numbers in each row sum up to 500 because the sampling-estimation procedure is repeated for 500 times for each simulation.}}{19}{table.1}}
\newlabel{tab:sim1}{{1}{19}{Distribution of Kendall distance between the true $\pi _{0}$ and the estimated ones. The results for two simulations with sample sizes 200 and 500. Type 'initial' represents the distance between the initial ranking (Borda count method) and true $\pi _{0}$, and type 'final' represents the distance between the ranking estimated by the algorithm and true $\pi _{0}$. The number in the cell represents the number of runs that the distance is observed. The numbers in each row sum up to 500 because the sampling-estimation procedure is repeated for 500 times for each simulation}{table.1}{}}
\newlabel{subsec:-Estimating-w-sim}{{7.1.3}{19}{}{subsubsection.7.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Visualization of true weights and estimated weights. The simulation involves 39 weight parameters, which are plotted across the horizontal axis. The true weight is represented as a red dot. The distribution of the estimated weight in the 500 runs is illustrated via a boxplot. The boxplot encodes the median, lower and upper quartiles, and outliers.}}{20}{figure.3}}
\newlabel{fig:sim-2-weights}{{3}{20}{Visualization of true weights and estimated weights. The simulation involves 39 weight parameters, which are plotted across the horizontal axis. The true weight is represented as a red dot. The distribution of the estimated weight in the 500 runs is illustrated via a boxplot. The boxplot encodes the median, lower and upper quartiles, and outliers}{figure.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Distribution of Kendall distance between the true $\pi _{0}$ and the estimated ones.}}{20}{table.2}}
\newlabel{tab:sim3}{{2}{20}{Distribution of Kendall distance between the true $\pi _{0}$ and the estimated ones}{table.2}{}}
\citation{Diaconis1988}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Visualization of true weights and estimated weights.}}{21}{figure.4}}
\newlabel{fig:sim-3-weights}{{4}{21}{Visualization of true weights and estimated weights}{figure.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Summary of the fitted models for complete rankingss}}{22}{table.3}}
\newlabel{tab:Summary-of-mod}{{3}{22}{Summary of the fitted models for complete rankingss}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Parameter estimates of the fitted models for complete ranking.}}{23}{table.4}}
\newlabel{tab:Parameters-of-mod}{{4}{23}{Parameter estimates of the fitted models for complete ranking}{table.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Visualization of APA data with fitted model.}}{24}{figure.5}}
\newlabel{fig:Visualization-of-APA}{{5}{24}{Visualization of APA data with fitted model}{figure.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Summary for the fitted models for all rankings.}}{24}{table.5}}
\newlabel{tab:sum-all}{{5}{24}{Summary for the fitted models for all rankings}{table.5}{}}
\citation{Klementiev2008}
\citation{KemedyNP}
\citation{Marden1995a}
\citation{lee2014cognitive}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Parameter estimates of the fitted models for all rankings.}}{25}{table.6}}
\newlabel{tab:Parameters-of-all}{{6}{25}{Parameter estimates of the fitted models for all rankings}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Rank aggregation results of 20 different data sets.}}{26}{table.7}}
\newlabel{tab:Rank-Aggregation-Results}{{7}{26}{Rank aggregation results of 20 different data sets}{table.7}{}}
\bibdata{paper_ref}
\bibcite{AlvoYu2014}{{1}{2014}{{Alvo and Yu}}{{}}}
\bibcite{KemedyNP}{{2}{1989}{{Bartholdi \emph  {et~al.}}}{{Bartholdi, Tovey, and Trick}}}
\bibcite{Critchlow1986}{{3}{1986}{{Critchlow}}{{}}}
\bibcite{mlogit}{{4}{2013}{{Croissant}}{{}}}
\bibcite{Diaconis1988}{{5}{1988}{{Diaconis}}{{}}}
\bibcite{dwork2001rank}{{6}{2001}{{Dwork \emph  {et~al.}}}{{Dwork, Kumar, Naor, and Sivakumar}}}
\bibcite{farnoud2014axiomatic}{{7}{2014}{{Farnoud and Milenkovic}}{{}}}
\bibcite{Fligner1986}{{8}{1986}{{Fligner and Verducci}}{{}}}
\bibcite{Fligner1988}{{9}{1988}{{Fligner and Verducci}}{{}}}
\bibcite{Rankcluster}{{10}{2014}{{Grimonprez and Jacques}}{{}}}
\bibcite{PerMallows}{{11}{2015}{{Irurozki}}{{}}}
\bibcite{ISR}{{12}{2012}{{Jacques and Biernacki}}{{}}}
\bibcite{Joe2001}{{13}{2001}{{Joe}}{{}}}
\bibcite{Klementiev2008}{{14}{2008}{{Klementiev \emph  {et~al.}}}{{Klementiev, Roth, and Small}}}
\bibcite{lee2014cognitive}{{15}{2014}{{Lee \emph  {et~al.}}}{{Lee, Steyvers, and Miller}}}
\bibcite{LeeYu2012}{{16}{2012}{{Lee and Yu}}{{}}}
\bibcite{pmr}{{17}{2015}{{Lee and Yu}}{{}}}
\bibcite{Luce1959}{{18}{1959}{{Luce}}{{}}}
\bibcite{Mallows1957}{{19}{1957}{{Mallows}}{{}}}
\bibcite{Marden1995a}{{20}{1995}{{Marden}}{{}}}
\bibcite{Murphy2003}{{21}{2003}{{Murphy and Martin}}{{}}}
\bibcite{nash2011unifying}{{22}{2011}{{Nash and Varadhan}}{{}}}
\bibcite{Smith1950}{{23}{1950}{{Smith}}{{}}}
\bibcite{R}{{24}{2014}{{Team}}{{}}}
\bibcite{Thurstone1927}{{25}{1927}{{Thurstone}}{{}}}
\bibcite{young1974axiomatization}{{26}{1974}{{Young}}{{}}}
\bibcite{Yu2000}{{27}{2000}{{Yu}}{{}}}
\citation{Fligner1988}
