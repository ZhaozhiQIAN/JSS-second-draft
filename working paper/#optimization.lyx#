#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{hyperref}
\usepackage{natbib}
\setcitestyle{round}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman "times" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Subsection
Parameter estimation
\end_layout

\begin_layout Subsubsection
Estimating central ranking 
\begin_inset Formula $\pi_{0}$
\end_inset


\end_layout

\begin_layout Standard
Given a set of weights 
\begin_inset Formula $w$
\end_inset

 and 
\begin_inset Formula $n$
\end_inset

 observed rankings 
\begin_inset Formula $\sigma_{1},\ldots,\sigma_{n}$
\end_inset

, finding the maximum likelihood estimate of central ranking 
\begin_inset Formula $\pi_{0}$
\end_inset

 is equivalent to minimize the total distance between 
\begin_inset Formula $\pi_{0}$
\end_inset

 and the observed rankings 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:rank-agg-obj"

\end_inset

.
\begin_inset Formula 
\begin{equation}
\pi_{0}=\argmin\left\{ \sum_{i=1}^{n}D_{wK}(\pi_{0},\sigma_{i})\right\} \label{eq:rank-agg-obj}
\end{equation}

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "dwork2001rank"

\end_inset

 studied this problem where the distance metric is the original Kendall
 distance, i.e.
 the weights are all equal.
 They showed that even when 
\begin_inset Formula $n=4$
\end_inset

, the problem is NP-complete.
 We have seen little evidence suggesting that introducing different weights
 will reduce the complexity of this problem.
 Therefore, in most cases the optimization algorithm will only be able to
 find a local optimal.
 A ranking 
\begin_inset Formula $\pi$
\end_inset

 is a local optimal of problem 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:rank-agg-obj"

\end_inset

 if there is no ranking 
\begin_inset Formula $\pi'$
\end_inset

 that can be obtained from 
\begin_inset Formula $\pi$
\end_inset

 by performing a single adjacent transposition and 
\begin_inset Formula $\sum_{i=1}^{n}D_{wK}(\pi,\sigma_{i})>\sum_{i=1}^{n}D_{wK}(\pi',\sigma_{i})$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "dwork2001rank"

\end_inset

 showed that in the equal-weighting case all the local optimals of problem
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:rank-agg-obj"

\end_inset

 have a desirable property, the extended Condorcet property.
 The extended Condorcet property requires that if there exists a partition
 of items 
\begin_inset Formula $(C,\,C')$
\end_inset

 such that for any 
\begin_inset Formula $x\in C$
\end_inset

 and 
\begin_inset Formula $y\in C'$
\end_inset

 the majority of 
\begin_inset Formula $\sigma_{1},\ldots,\sigma_{n}$
\end_inset

 prefers 
\begin_inset Formula $x$
\end_inset

 over 
\begin_inset Formula $y$
\end_inset

, then 
\begin_inset Formula $x$
\end_inset

 must be ranked above 
\begin_inset Formula $y$
\end_inset

.
 Roughly speaking, the extended Condorcet property ensures that the 
\begin_inset Quotes eld
\end_inset

consensus
\begin_inset Quotes erd
\end_inset

 in the observed rankings are preserved in the aggregated ranking.
 Not all rank aggregation algorithm has extended Condorcet property and
 the Borda count algorithm is such an exception 
\begin_inset CommandInset citation
LatexCommand cite
key "young1974axiomatization"

\end_inset

.
 
\end_layout

\begin_layout Standard
When the weights are different, the local optimals of problem 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:rank-agg-obj"

\end_inset

 do not have extended Condorcet property either, but this should be preceived
 as a feature of the weighted Kendall distance.
 Essentially, the weighted Kendall distance captures the senario when the
 disagreement at the top of the ranked list of objects matters more then
 the one at the bottom.
 Hence, both the number of disagreements (consenses) and the location of
 the disagreements will affect the weighted Kendall aggregation while the
 extended Condorcet property does not take the location into account.
 
\end_layout

\begin_layout Standard
We propose the following huristic algorithm to find local optimals.
 The algorithm is provided with an initial value of 
\begin_inset Formula $\pi_{0}$
\end_inset

, denoted as 
\begin_inset Formula $\pi_{00}$
\end_inset

.
 This initial value could be a frequently observed ranking or the result
 of another rank aggregation algorithm such as the Borda count algorithm.
 Then all its neighboring rankings are considered and their log-likelihoods
 are calculated.
 If 
\begin_inset Formula $\pi_{00}$
\end_inset

 achieves the largest likelihood among all its neighbouts then we have found
 the local optimum and the algorithm stops.
 Otherwise, we select the one with the largest likelihood as 
\begin_inset Formula $\pi_{01}$
\end_inset

 and consider all of its neighbors again.
 This process repeats until 
\begin_inset Formula $\pi_{0k}$
\end_inset

 has larger likelihood than all its neighbors.
 Since in each step, the objective function 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:rank-agg-obj"

\end_inset

 always decrease, the algorithm will stop eventually.
 In section 
\begin_inset Note Note
status open

\begin_layout Plain Layout
add section reference: simulation of finding pi0
\end_layout

\end_inset

we evaluate this huristic algorithm with simulation studies.
 The simulation result shows that when the observed rankings are generated
 by weighted Kendall model, the algorithm is likely to find the true ranking
 even when the number of objects are large (~40) and the sample size is
 small (~200).
 
\end_layout

\begin_layout Subsubsection
Estimating weights 
\begin_inset Formula $w$
\end_inset


\end_layout

\begin_layout Standard
The weights in the weighted Kendall distance is closely related to the 'dispersi
on' of rankings.
 They also indicate the relative importance of locations in the ranked list.
 Hence, the estimation of weights is an important part of the model.
\end_layout

\begin_layout Standard
For the weighted Kendall model the log-likelihood function is given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\ell(\pi_{1},\pi_{2},...,\pi_{n})=-\sum_{i=1}^{n}\sum_{j=1}^{t-1}w_{j}Q_{j}(\pi_{i},\pi_{0})-n\log(C_{wK}(\boldsymbol{w})),
\]

\end_inset

where
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $Q_{j}(\pi_{i},\pi_{0})$
\end_inset

 are defined as in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:3"

\end_inset

), and they are constants if
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 
\begin_inset Formula $\pi_{0}$
\end_inset

 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
is given.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 In section 
\begin_inset Note Note
status open

\begin_layout Plain Layout
add section reference: normalizing constant
\end_layout

\end_inset

 we've shown that the logrithm of the normalizing constant 
\begin_inset Formula $C_{wK}(\boldsymbol{w})$
\end_inset

 is a convex function in 
\begin_inset Formula $w$
\end_inset

.
 It follows that the log-likelihood function is a concave function in 
\begin_inset Formula $w$
\end_inset

.
 Since the non-decreasing constraint on 
\begin_inset Formula $w$
\end_inset

 is a linear inequality constraint, the problem of finding maximum likelihood
 estimate of 
\begin_inset Formula $w$
\end_inset

 is a convex optimization problem, which has a global optimal solution.
 
\end_layout

\begin_layout Standard
In practice, we reparametrize 
\begin_inset Formula $w_{j}$
\end_inset

 as 
\begin_inset Formula $w_{j}=\sum_{i=j}^{t-1}\phi_{i}$
\end_inset

, where 
\begin_inset Formula $\phi_{i}\geq0$
\end_inset

 for all 
\begin_inset Formula $i$
\end_inset

, and transform the non-increasing constraint on 
\begin_inset Formula $w$
\end_inset

 into a box constraint on 
\begin_inset Formula $\phi$
\end_inset

.
 The log-likelihood function is still concave and it can be rewritten in
 terms of 
\begin_inset Formula $\phi$
\end_inset

 as:
\begin_inset Formula 
\[
\ell(\pi_{1},\pi_{2},...,\pi_{n})=-\sum_{i=1}^{n}\sum_{j=1}^{t-1}\phi_{j}\left[\sum_{k=j}^{t-1}Q_{k}(\pi_{i},\pi_{0})\right]-n\log(C_{wK}(\boldsymbol{w}(\boldsymbol{\phi}))).
\]

\end_inset


\end_layout

\begin_layout Standard
With the simplified constraint, we can apply a general convex optimization
 solver to estimate 
\begin_inset Formula $w$
\end_inset

.
 The L-BFGS-B method in the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
proglang{R}
\end_layout

\end_inset

 package 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
pkg{Optimx}
\end_layout

\end_inset

 is used for the optimization in 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
pkg{rankdist}
\end_layout

\end_inset

.
 The simulation studies in section 
\begin_inset Note Note
status open

\begin_layout Plain Layout
add section reference: simulation of finding w
\end_layout

\end_inset

 confirms that the optimization procedure is reliable.
 
\end_layout

\begin_layout Subsubsection
Estimating central ranking 
\begin_inset Formula $\pi_{0}$
\end_inset

 and weights 
\begin_inset Formula $w$
\end_inset

 jointly
\end_layout

\begin_layout Standard
In most cases, neither 
\begin_inset Formula $\pi_{0}$
\end_inset

 nor 
\begin_inset Formula $w$
\end_inset

 is known to us and both need to be estimated from the data.
 It is hard to estimate 
\begin_inset Formula $\pi_{0}$
\end_inset

 and 
\begin_inset Formula $w$
\end_inset

 simuntanously because 
\begin_inset Formula $\pi_{0}$
\end_inset

 is a ranking while 
\begin_inset Formula $w$
\end_inset

 is a vector of real numbers.
 Instead, we apply a stage-wise method that iteratively searches for the
 two paramters.
 
\end_layout

\begin_layout Standard
The algorithm is provided with an initial value of 
\begin_inset Formula $\pi_{0}$
\end_inset

, denoted as 
\begin_inset Formula $\pi_{00}$
\end_inset

, which can be the result of any rank aggregation algorithm.
 The algorithm finds the optimal weights for 
\begin_inset Formula $\pi_{00}$
\end_inset

 and records the resulting log-likelihood value.
 Then all the neighboring rankings of 
\begin_inset Formula $\pi_{00}$
\end_inset

 are considered.
 For each of them, the algorithm finds the optimal weights 
\begin_inset Formula $w$
\end_inset

 and calculate the resulting log-likelihood value.
 If 
\begin_inset Formula $\pi_{00}$
\end_inset

 achieves the largest likelihood among all its neighbouts then we have found
 the local optimum and the algorithm stops.
 Otherwise, we select the one with the largest likelihood as 
\begin_inset Formula $\pi_{01}$
\end_inset

 and consider all of its neighbors again.
 This process repeats until 
\begin_inset Formula $\pi_{0k}$
\end_inset

 has larger likelihood than all its neighbors.
 Since in each step, the objective function 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:rank-agg-obj"

\end_inset

 always decrease, the algorithm will stop eventually.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "paper_ref"
options "apalike"

\end_inset


\end_layout

\end_body
\end_document
